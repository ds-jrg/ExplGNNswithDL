{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daily-cycling",
   "metadata": {},
   "source": [
    "First download NCESData.zip from [hobbit](https://hobbitdata.informatik.uni-leipzig.de/NCES_Ontolearn_Data/) and extract it into the Ontolearn repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "supported-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ontolearn.concept_learner import NCES\n",
    "from ontolearn.knowledge_base import KnowledgeBase\n",
    "from owlapy.parser import DLSyntaxParser\n",
    "from owlapy.render import DLSyntaxObjectRenderer\n",
    "from ontolearn.metrics import F1, Accuracy, Precision, Recall\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minor-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(solution, pos, neg):\n",
    "    f1 = F1().score2; accuracy = Accuracy().score2; precision = Precision().score2; recall = Recall().score2\n",
    "    instances = set(KB.individuals(solution))\n",
    "    if isinstance(list(pos)[0], str):\n",
    "        instances = {ind.get_iri().as_str().split(\"/\")[-1] for ind in instances}\n",
    "    tp=len(pos.intersection(instances))\n",
    "    fn=len((instances-pos).difference(neg))\n",
    "    fp=len((instances-neg).difference(pos))\n",
    "    tn=len((instances-pos).intersection(neg))\n",
    "    print(\"Accuracy: {}%\".format(100*accuracy(tp, fn, fp, tn)[-1]))\n",
    "    print(\"Precision: {}%\".format(100*precision(tp, fn, fp, tn)[-1]))\n",
    "    print(\"Recall: {}%\".format(100*recall(tp, fn, fp, tn)[-1]))\n",
    "    print(\"F1: {}%\".format(100*f1(tp, fn, fp, tn)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "latin-keeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Loaded pretrained model! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nces = NCES(knowledge_base_path=\"../NCESData/family/family.owl\", learner_name=\"SetTransformer\",\n",
    "     path_of_embeddings=\"../NCESData/family/embeddings/ConEx_entity_embeddings.csv\", load_pretrained=True, max_length=48, proj_dim=128, rnn_n_layers=2, drop_prob=0.1, num_heads=4, num_seeds=1, num_inds=32, pretrained_model_name=\"SetTransformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hollow-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "KB = KnowledgeBase(path=nces.knowledge_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "superb-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_syntax_renderer = DLSyntaxObjectRenderer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pretty-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_classes = [dl_syntax_renderer.render(a) for a in KB.ontology().classes_in_signature()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "premier-variable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brother',\n",
       " 'Male',\n",
       " 'PersonWithASibling',\n",
       " 'Child',\n",
       " 'Person',\n",
       " 'Daughter',\n",
       " 'Female',\n",
       " 'Father',\n",
       " 'Parent',\n",
       " 'Grandchild',\n",
       " 'Granddaughter',\n",
       " 'Grandfather',\n",
       " 'Grandparent',\n",
       " 'Grandmother',\n",
       " 'Grandson',\n",
       " 'Mother',\n",
       " 'Sister',\n",
       " 'Son']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fifth-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_parser = DLSyntaxParser(nces.kb_namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spoken-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "brother = dl_parser.parse('Brother')\n",
    "daughter = dl_parser.parse('Daughter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-moment",
   "metadata": {},
   "source": [
    "#### Input examples can be sets or lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "effective-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = set(KB.individuals(brother)).union(set(KB.individuals(daughter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "individual-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = set(KB.individuals())-set(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-operation",
   "metadata": {},
   "source": [
    "#### Prediction with SetTransformer (default model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "level-happiness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  Son ⊔ Daughter ⊔ PersonWithASibling\n",
      "\n",
      "Duration:  0.13891911506652832  seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "concept = nces.fit(pos, neg)\n",
    "t1 = time.time()\n",
    "print(\"\\nDuration: \", t1-t0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "later-remainder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1: 100.0%\n"
     ]
    }
   ],
   "source": [
    "quality(concept, pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-faculty",
   "metadata": {},
   "source": [
    "### Ensemble prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "comprehensive-display",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Loaded pretrained model! \n",
      "\n",
      "\n",
      "\n",
      " Loaded pretrained model! \n",
      "\n",
      "\n",
      "\n",
      " Loaded pretrained model! \n",
      "\n",
      "Prediction:  Brother ⊔ Daughter\n",
      "\n",
      "Duration:  0.4016838073730469  seconds\n"
     ]
    }
   ],
   "source": [
    "nces.pretrained_model_name = ['SetTransformer','GRU','LSTM']\n",
    "nces.refresh()\n",
    "t0 = time.time()\n",
    "concept = nces.fit(pos, neg)\n",
    "t1 = time.time()\n",
    "print(\"\\nDuration: \", t1-t0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "limiting-capitol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1: 100.0%\n"
     ]
    }
   ],
   "source": [
    "quality(concept, pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-research",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "female-elite",
   "metadata": {},
   "source": [
    "### Complex learning problems, potentially without an exact solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-hearing",
   "metadata": {},
   "source": [
    "#### First learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "flexible-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_individuals = set(KB.individuals())\n",
    "pos = set(random.sample(list(all_individuals), 150))\n",
    "remaining = all_individuals-pos\n",
    "neg = set(random.sample(list(remaining), min(100, len(remaining))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "departmental-latvia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SetTransformer', 'GRU', 'LSTM']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nces.pretrained_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "developmental-perth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  Person ⊓ (∀ married.(PersonWithASibling ⊔ (∀ hasChild.(¬Sister))))\n",
      "\n",
      "Duration:  0.34989166259765625  seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "concept = nces.fit(pos, neg)\n",
    "t1 = time.time()\n",
    "print(\"\\nDuration: \", t1-t0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fluid-entrance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1: 100.0%\n"
     ]
    }
   ],
   "source": [
    "quality(concept, pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-lecture",
   "metadata": {},
   "source": [
    "#### Second learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "requested-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = set(random.sample(list(all_individuals), 80))\n",
    "remaining = all_individuals-pos\n",
    "neg = set(random.sample(list(remaining), min(150, len(remaining))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "potential-blackberry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  Person ⊔ Male\n",
      "\n",
      "Duration:  0.3551011085510254  seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "concept = nces.fit(pos, neg)\n",
    "t1 = time.time()\n",
    "print(\"\\nDuration: \", t1-t0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "appreciated-western",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall: 100.0%\n",
      "F1: 100.0%\n"
     ]
    }
   ],
   "source": [
    "quality(concept, pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-edward",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "infrared-fraud",
   "metadata": {},
   "source": [
    "## Important note\n",
    "\n",
    "- Each of the synthesized expressions, e.g., Person ⊓ (∀ married.(PersonWithASibling ⊔ (∀ hasChild.(¬Sister)))) are not present in the knowledge base.\n",
    "- NCES synthesizes solutions by leveraging its experience on the training data.\n",
    "- The inputs (positive/negative examples) need not be balanced\n",
    "- NCES can solve multiple learning problems at the same time (through broadcasting on matrix operations in its neural network component)\n",
    "- Since LSTM and GRU are not permutation-equivariant, we can get different but closely related solutions by shuflling the input examples for these architectures. For this, one needs to instantiate the NCES class with the attribute \"sorted_examples=False\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-focus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nces",
   "language": "python",
   "name": "nces"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
